{
  "nodes": [
    {
      "id": "supervisor_0",
      "position": {
        "x": 669,
        "y": 255
      },
      "type": "customNode",
      "data": {
        "id": "supervisor_0",
        "label": "Supervisor",
        "version": 3,
        "name": "supervisor",
        "type": "Supervisor",
        "baseClasses": [
          "Supervisor"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Supervisor Name",
            "name": "supervisorName",
            "type": "string",
            "placeholder": "Supervisor",
            "default": "Supervisor",
            "id": "supervisor_0-input-supervisorName-string",
            "display": true
          },
          {
            "label": "Supervisor Prompt",
            "name": "supervisorPrompt",
            "type": "string",
            "description": "Prompt must contains {team_members}",
            "rows": 4,
            "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
            "additionalParams": true,
            "id": "supervisor_0-input-supervisorPrompt-string",
            "display": true
          },
          {
            "label": "Summarization",
            "name": "summarization",
            "type": "boolean",
            "description": "Return final output as a summarization of the conversation",
            "optional": true,
            "additionalParams": true,
            "id": "supervisor_0-input-summarization-boolean",
            "display": true
          },
          {
            "label": "Recursion Limit",
            "name": "recursionLimit",
            "type": "number",
            "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
            "default": 100,
            "additionalParams": true,
            "id": "supervisor_0-input-recursionLimit-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
            "id": "supervisor_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "supervisor_0-input-agentMemory-BaseCheckpointSaver",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "supervisor_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "supervisorName": "Supervisor",
          "supervisorPrompt": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.\n\nYou start with the storyteller and pass output to the title creator",
          "model": "{{groqChat_0.data.instance}}",
          "agentMemory": "",
          "summarization": "",
          "recursionLimit": 100,
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "supervisor_0-output-supervisor-Supervisor",
            "name": "supervisor",
            "label": "Supervisor",
            "description": "",
            "type": "Supervisor"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 489,
      "positionAbsolute": {
        "x": 669,
        "y": 255
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": -21.991045245932753,
        "y": 60.59015293316503
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number",
            "display": true
          },
          {
            "label": "Safety Settings",
            "name": "safetySettings",
            "type": "array",
            "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-settings\">official guide</a> on how to use Safety Settings",
            "array": [
              {
                "label": "Harm Category",
                "name": "harmCategory",
                "type": "options",
                "options": [
                  {
                    "label": "Dangerous",
                    "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "description": "Promotes, facilitates, or encourages harmful acts."
                  },
                  {
                    "label": "Harassment",
                    "name": "HARM_CATEGORY_HARASSMENT",
                    "description": "Negative or harmful comments targeting identity and/or protected attributes."
                  },
                  {
                    "label": "Hate Speech",
                    "name": "HARM_CATEGORY_HATE_SPEECH",
                    "description": "Content that is rude, disrespectful, or profane."
                  },
                  {
                    "label": "Sexually Explicit",
                    "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "description": "Contains references to sexual acts or other lewd content."
                  },
                  {
                    "label": "Civic Integrity",
                    "name": "HARM_CATEGORY_CIVIC_INTEGRITY",
                    "description": "Election-related queries."
                  }
                ]
              },
              {
                "label": "Harm Block Threshold",
                "name": "harmBlockThreshold",
                "type": "options",
                "options": [
                  {
                    "label": "None",
                    "name": "BLOCK_NONE",
                    "description": "Always show regardless of probability of unsafe content"
                  },
                  {
                    "label": "Only High",
                    "name": "BLOCK_ONLY_HIGH",
                    "description": "Block when high probability of unsafe content"
                  },
                  {
                    "label": "Medium and Above",
                    "name": "BLOCK_MEDIUM_AND_ABOVE",
                    "description": "Block when medium or high probability of unsafe content"
                  },
                  {
                    "label": "Low and Above",
                    "name": "BLOCK_LOW_AND_ABOVE",
                    "description": "Block when low, medium or high probability of unsafe content"
                  },
                  {
                    "label": "Threshold Unspecified (Default Threshold)",
                    "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                    "description": "Threshold is unspecified, block using default threshold"
                  }
                ]
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-safetySettings-array",
            "display": true
          },
          {
            "label": "Thinking Budget",
            "name": "thinkingBudget",
            "type": "number",
            "description": "Guides the number of thinking tokens. -1 for dynamic, 0 to disable, or positive integer (Gemini 2.5 models).",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "show": {
              "modelName": [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-2.5-flash-lite"
              ]
            },
            "id": "chatGoogleGenerativeAI_0-input-thinkingBudget-number",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-2.5-flash",
          "customModelName": "",
          "temperature": 0.9,
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "safetySettings": "",
          "thinkingBudget": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": -21.991045245932753,
        "y": 60.59015293316503
      },
      "dragging": false
    },
    {
      "id": "worker_0",
      "position": {
        "x": 1071.9066830758607,
        "y": 99.19946899950938
      },
      "type": "customNode",
      "data": {
        "id": "worker_0",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_0-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_0-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_0-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_0-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_0-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_0-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "storyteller",
          "workerPrompt": "You are a story writer. Your goal is to write interesting stories about animals for kids aged 8-10 years old. Your stories are funny and 500 words long.\nWhen you are done, you give your output to the title creator.",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 728,
      "positionAbsolute": {
        "x": 1071.9066830758607,
        "y": 99.19946899950938
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "worker_1",
      "position": {
        "x": 1420.905636516198,
        "y": 111.21202771546342
      },
      "type": "customNode",
      "data": {
        "id": "worker_1",
        "label": "Worker (1)",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_1-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_1-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_1-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_1-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_1-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_1-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_1-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "title creator",
          "workerPrompt": "You are a title creator, you make 10 titles that are perfect for the story from the storyteller.",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 728,
      "positionAbsolute": {
        "x": 1420.905636516198,
        "y": 111.21202771546342
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": 308.05210958025083,
        "y": 53.08732508614574
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.3,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning",
            "description": "Whether the model supports reasoning. Only applicable for reasoning models.",
            "name": "reasoning",
            "type": "boolean",
            "default": false,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoning-boolean",
            "display": true
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": false
          },
          {
            "label": "Reasoning Summary",
            "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process",
            "name": "reasoningSummary",
            "type": "options",
            "options": [
              {
                "label": "Auto",
                "name": "auto"
              },
              {
                "label": "Concise",
                "name": "concise"
              },
              {
                "label": "Detailed",
                "name": "detailed"
              }
            ],
            "additionalParams": true,
            "show": {
              "reasoning": true
            },
            "id": "chatOpenAI_0-input-reasoningSummary-options",
            "display": false
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoning": "",
          "reasoningEffort": "",
          "reasoningSummary": ""
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 308.05210958025083,
        "y": 53.08732508614574
      }
    },
    {
      "id": "groqChat_0",
      "position": {
        "x": 299.49160488163733,
        "y": 747.3138380084796
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_0",
        "label": "GroqChat",
        "version": 4,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "groqChat_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "id": "groqChat_0-input-streaming-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "llama-3.1-8b-instant",
          "temperature": 0.9,
          "maxTokens": "",
          "streaming": true
        },
        "outputAnchors": [
          {
            "id": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "positionAbsolute": {
        "x": 299.49160488163733,
        "y": 747.3138380084796
      },
      "selected": false,
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_0",
      "targetHandle": "worker_0-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_1",
      "targetHandle": "worker_1-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_1-worker_1-input-supervisor-Supervisor"
    },
    {
      "source": "groqChat_0",
      "sourceHandle": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "groqChat_0-groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
    }
  ]
}